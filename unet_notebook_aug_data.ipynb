{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc79dbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "import random\n",
    "\n",
    "\n",
    "import cv2\n",
    "\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from utils import *\n",
    "from tqdm.auto import tqdm as tq\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "sns.set(style='white', context='notebook', palette='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51332897",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_folder='aug_images'\n",
    "mask_folder = 'aug_masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94f0d38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that for each image there is a mask , difference 0 indicate everything is okay\n",
    "image_ID,mask_ID = [],[]\n",
    "for x in os.listdir(img_folder):\n",
    "    y = x.replace('.png','')\n",
    "    image_ID.append(y)\n",
    "for x in os.listdir(mask_folder):\n",
    "    y = x.replace('.png','')\n",
    "    mask_ID.append(y) \n",
    "print(len(image_ID))\n",
    "print(len(mask_ID))\n",
    "print(len(set(image_ID).difference(set(mask_ID))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "335819cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just looking at a random image and its masks\n",
    "t1 = Image.open(os.path.join('aug_masks',os.listdir('aug_masks')[378]))\n",
    "t2 = Image.open(os.path.join('aug_images',os.listdir('aug_images')[378]))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(t1)\n",
    "plt.title(\"mask_image\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(t2)\n",
    "plt.title(\"train_image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99293f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting the actual code\n",
    "# please note new image data are already resized to 512 ,so no need to resize this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a37fd8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(image,n_classes):\n",
    "    x = F.one_hot(image,n_classes)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ac9d678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 512, 512]) torch.Size([27, 512, 512])\n",
      "torch.float32 torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Convert a PIL Image to tensor.\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.name = os.listdir(os.path.join(path, 'aug_masks'))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.name)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        name = self.name[index]\n",
    "        msk_path = os.path.join(self.path, 'aug_masks', name)\n",
    "        img_path = os.path.join(self.path, 'aug_images', name)\n",
    "        \n",
    "        img = Image.open(img_path)\n",
    "        mask = Image.open(msk_path)\n",
    "        \n",
    "        numpy_img = np.asarray(img)\n",
    "        numpy_mask = np.asarray(mask)\n",
    "        \n",
    "        tensor_mask = torch.from_numpy(numpy_mask).to(torch.int64)\n",
    "        ohe_mask = one_hot_encode(tensor_mask,27)\n",
    "        \n",
    "        \n",
    "        return transform(numpy_img),transform(np.asarray(ohe_mask).astype('float32'))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data = MyDataset('')\n",
    "    X = data[0][0]\n",
    "    y = data[0][1]\n",
    "    print(X.shape,y.shape)\n",
    "    print(X.dtype,y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d12baa7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 512, 512]) torch.Size([8, 27, 512, 512])\n",
      "torch.float32 torch.float32\n"
     ]
    }
   ],
   "source": [
    "full_dataset = MyDataset('')\n",
    "bs = 10\n",
    "nw = 0\n",
    "# Splitting into Train and Val\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size   = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# Creating  data_loader\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "it, lt = next(iter(train_loader))\n",
    "print(it.shape,lt.shape)\n",
    "print(it.dtype,lt.dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f38e78",
   "metadata": {},
   "source": [
    "# In Tensorflow, the channel position is at the end, but in PyTorch the format is \"Batch Size x Channel x Height x Width\"?\n",
    "\n",
    "https://stackoverflow.com/questions/59648324/pytorch-tensor-how-to-switch-channel-position-runtime-error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3ee4ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(img1, img2):\n",
    "    img1 = np.asarray(img1).astype(np.bool)\n",
    "    img2 = np.asarray(img2).astype(np.bool)\n",
    "\n",
    "    intersection = np.logical_and(img1, img2)\n",
    "\n",
    "    return 2.0 * intersection.sum() / (img1.sum() + img2.sum())\n",
    "\n",
    "\n",
    "def dice_no_threshold(\n",
    "    outputs: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    eps: float = 1e-7,\n",
    "    threshold: float = None,\n",
    "):\n",
    "    if threshold is not None:\n",
    "        outputs = (outputs > threshold).float()\n",
    "\n",
    "    intersection = torch.sum(targets * outputs)\n",
    "    union = torch.sum(targets) + torch.sum(outputs)\n",
    "    dice = 2 * intersection / (union + eps)\n",
    "\n",
    "    return dice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87fd37ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_score(pr, gt, beta=1, eps=1e-7, threshold=None, activation='sigmoid'):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        pr (torch.Tensor): A list of predicted elements\n",
    "        gt (torch.Tensor):  A list of elements that are to be predicted\n",
    "        eps (float): epsilon to avoid zero division\n",
    "        threshold: threshold for outputs binarization\n",
    "    Returns:\n",
    "        float: IoU (Jaccard) score\n",
    "    \"\"\"\n",
    "\n",
    "    if activation is None or activation == \"none\":\n",
    "        activation_fn = lambda x: x\n",
    "    elif activation == \"sigmoid\":\n",
    "        activation_fn = torch.nn.Sigmoid()\n",
    "    elif activation == \"softmax2d\":\n",
    "        activation_fn = torch.nn.Softmax2d()\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            \"Activation implemented for sigmoid and softmax2d\"\n",
    "        )\n",
    "\n",
    "    pr = activation_fn(pr)\n",
    "\n",
    "    if threshold is not None:\n",
    "        pr = (pr > threshold).float()\n",
    "\n",
    "\n",
    "    tp = torch.sum(gt * pr)\n",
    "    fp = torch.sum(pr) - tp\n",
    "    fn = torch.sum(gt) - tp\n",
    "    score = ((1 + beta ** 2) * tp + eps) \\\n",
    "            / ((1 + beta ** 2) * tp + beta ** 2 * fn + fp + eps)\n",
    "\n",
    "    return score\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    __name__ = 'dice_loss'\n",
    "\n",
    "    def __init__(self, eps=1e-7, activation='sigmoid'):\n",
    "        super().__init__()\n",
    "        self.activation = activation\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, y_pr, y_gt):\n",
    "        return 1 - f_score(y_pr, y_gt, beta=1., \n",
    "                           eps=self.eps, threshold=None, \n",
    "                           activation=self.activation)\n",
    "\n",
    "\n",
    "class BCEDiceLoss(DiceLoss):\n",
    "    __name__ = 'bce_dice_loss'\n",
    "\n",
    "    def __init__(self, eps=1e-7, activation='sigmoid', lambda_dice=1.0, lambda_bce=1.0):\n",
    "        super().__init__(eps, activation)\n",
    "        if activation == None:\n",
    "            self.bce = nn.BCELoss(reduction='mean')\n",
    "        else:\n",
    "            self.bce = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "        self.lambda_dice=lambda_dice\n",
    "        self.lambda_bce=lambda_bce\n",
    "\n",
    "    def forward(self, y_pr, y_gt):\n",
    "        dice = super().forward(y_pr, y_gt)\n",
    "        bce = self.bce(y_pr, y_gt)\n",
    "        return (self.lambda_dice*dice) + (self.lambda_bce* bce)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b637b2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAdam(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
    "        if not 0.0 <= lr:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if not 0.0 <= eps:\n",
    "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
    "            \n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "        self.buffer = [[None, None, None] for ind in range(10)]\n",
    "        super(RAdam, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(RAdam, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                state['step'] += 1\n",
    "                buffered = self.buffer[int(state['step'] % 10)]\n",
    "                if state['step'] == buffered[0]:\n",
    "                    N_sma, step_size = buffered[1], buffered[2]\n",
    "                else:\n",
    "                    buffered[0] = state['step']\n",
    "                    beta2_t = beta2 ** state['step']\n",
    "                    N_sma_max = 2 / (1 - beta2) - 1\n",
    "                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
    "                    buffered[1] = N_sma\n",
    "\n",
    "                    # more conservative since it's an approximated value\n",
    "                    if N_sma >= 5:\n",
    "                        step_size = math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
    "                    else:\n",
    "                        step_size = 1.0 / (1 - beta1 ** state['step'])\n",
    "                    buffered[2] = step_size\n",
    "\n",
    "                if group['weight_decay'] != 0:\n",
    "                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "\n",
    "                # more conservative since it's an approximated value\n",
    "                if N_sma >= 5:            \n",
    "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                    p_data_fp32.addcdiv_(-step_size * group['lr'], exp_avg, denom)\n",
    "                else:\n",
    "                    p_data_fp32.add_(-step_size * group['lr'], exp_avg)\n",
    "\n",
    "                p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e3d24d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNET model\n",
    "\n",
    "class double_conv(nn.Module):\n",
    "    \"\"\"(conv => BN => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(double_conv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            #nn.Dropout2d(0.3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class inconv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(inconv, self).__init__()\n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(down, self).__init__()\n",
    "        self.mpconv = nn.Sequential(nn.MaxPool2d(2), double_conv(in_ch, out_ch))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mpconv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, bilinear=True):\n",
    "        super(up, self).__init__()\n",
    "\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_ch // 2, in_ch // 2, 2, stride=2)\n",
    "\n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, (diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2))\n",
    "        \n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class outconv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(outconv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(UNet, self).__init__()\n",
    "        self.inc = inconv(n_channels, 64)\n",
    "        self.down1 = down(64, 128)\n",
    "        self.down2 = down(128, 256)\n",
    "        self.down3 = down(256, 512)\n",
    "        self.down4 = down(512, 512)\n",
    "        self.up1 = up(1024, 256, False)\n",
    "        self.up2 = up(512, 128, False)\n",
    "        self.up3 = up(256, 64, False)\n",
    "        self.up4 = up(128, 64, False)\n",
    "        self.outc = outconv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        x = self.outc(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "532ceade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 512, 512]           1,792\n",
      "       BatchNorm2d-2         [-1, 64, 512, 512]             128\n",
      "              ReLU-3         [-1, 64, 512, 512]               0\n",
      "            Conv2d-4         [-1, 64, 512, 512]          36,928\n",
      "       BatchNorm2d-5         [-1, 64, 512, 512]             128\n",
      "              ReLU-6         [-1, 64, 512, 512]               0\n",
      "       double_conv-7         [-1, 64, 512, 512]               0\n",
      "            inconv-8         [-1, 64, 512, 512]               0\n",
      "         MaxPool2d-9         [-1, 64, 256, 256]               0\n",
      "           Conv2d-10        [-1, 128, 256, 256]          73,856\n",
      "      BatchNorm2d-11        [-1, 128, 256, 256]             256\n",
      "             ReLU-12        [-1, 128, 256, 256]               0\n",
      "           Conv2d-13        [-1, 128, 256, 256]         147,584\n",
      "      BatchNorm2d-14        [-1, 128, 256, 256]             256\n",
      "             ReLU-15        [-1, 128, 256, 256]               0\n",
      "      double_conv-16        [-1, 128, 256, 256]               0\n",
      "             down-17        [-1, 128, 256, 256]               0\n",
      "        MaxPool2d-18        [-1, 128, 128, 128]               0\n",
      "           Conv2d-19        [-1, 256, 128, 128]         295,168\n",
      "      BatchNorm2d-20        [-1, 256, 128, 128]             512\n",
      "             ReLU-21        [-1, 256, 128, 128]               0\n",
      "           Conv2d-22        [-1, 256, 128, 128]         590,080\n",
      "      BatchNorm2d-23        [-1, 256, 128, 128]             512\n",
      "             ReLU-24        [-1, 256, 128, 128]               0\n",
      "      double_conv-25        [-1, 256, 128, 128]               0\n",
      "             down-26        [-1, 256, 128, 128]               0\n",
      "        MaxPool2d-27          [-1, 256, 64, 64]               0\n",
      "           Conv2d-28          [-1, 512, 64, 64]       1,180,160\n",
      "      BatchNorm2d-29          [-1, 512, 64, 64]           1,024\n",
      "             ReLU-30          [-1, 512, 64, 64]               0\n",
      "           Conv2d-31          [-1, 512, 64, 64]       2,359,808\n",
      "      BatchNorm2d-32          [-1, 512, 64, 64]           1,024\n",
      "             ReLU-33          [-1, 512, 64, 64]               0\n",
      "      double_conv-34          [-1, 512, 64, 64]               0\n",
      "             down-35          [-1, 512, 64, 64]               0\n",
      "        MaxPool2d-36          [-1, 512, 32, 32]               0\n",
      "           Conv2d-37          [-1, 512, 32, 32]       2,359,808\n",
      "      BatchNorm2d-38          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-39          [-1, 512, 32, 32]               0\n",
      "           Conv2d-40          [-1, 512, 32, 32]       2,359,808\n",
      "      BatchNorm2d-41          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-42          [-1, 512, 32, 32]               0\n",
      "      double_conv-43          [-1, 512, 32, 32]               0\n",
      "             down-44          [-1, 512, 32, 32]               0\n",
      "  ConvTranspose2d-45          [-1, 512, 64, 64]       1,049,088\n",
      "           Conv2d-46          [-1, 256, 64, 64]       2,359,552\n",
      "      BatchNorm2d-47          [-1, 256, 64, 64]             512\n",
      "             ReLU-48          [-1, 256, 64, 64]               0\n",
      "           Conv2d-49          [-1, 256, 64, 64]         590,080\n",
      "      BatchNorm2d-50          [-1, 256, 64, 64]             512\n",
      "             ReLU-51          [-1, 256, 64, 64]               0\n",
      "      double_conv-52          [-1, 256, 64, 64]               0\n",
      "               up-53          [-1, 256, 64, 64]               0\n",
      "  ConvTranspose2d-54        [-1, 256, 128, 128]         262,400\n",
      "           Conv2d-55        [-1, 128, 128, 128]         589,952\n",
      "      BatchNorm2d-56        [-1, 128, 128, 128]             256\n",
      "             ReLU-57        [-1, 128, 128, 128]               0\n",
      "           Conv2d-58        [-1, 128, 128, 128]         147,584\n",
      "      BatchNorm2d-59        [-1, 128, 128, 128]             256\n",
      "             ReLU-60        [-1, 128, 128, 128]               0\n",
      "      double_conv-61        [-1, 128, 128, 128]               0\n",
      "               up-62        [-1, 128, 128, 128]               0\n",
      "  ConvTranspose2d-63        [-1, 128, 256, 256]          65,664\n",
      "           Conv2d-64         [-1, 64, 256, 256]         147,520\n",
      "      BatchNorm2d-65         [-1, 64, 256, 256]             128\n",
      "             ReLU-66         [-1, 64, 256, 256]               0\n",
      "           Conv2d-67         [-1, 64, 256, 256]          36,928\n",
      "      BatchNorm2d-68         [-1, 64, 256, 256]             128\n",
      "             ReLU-69         [-1, 64, 256, 256]               0\n",
      "      double_conv-70         [-1, 64, 256, 256]               0\n",
      "               up-71         [-1, 64, 256, 256]               0\n",
      "  ConvTranspose2d-72         [-1, 64, 512, 512]          16,448\n",
      "           Conv2d-73         [-1, 64, 512, 512]          73,792\n",
      "      BatchNorm2d-74         [-1, 64, 512, 512]             128\n",
      "             ReLU-75         [-1, 64, 512, 512]               0\n",
      "           Conv2d-76         [-1, 64, 512, 512]          36,928\n",
      "      BatchNorm2d-77         [-1, 64, 512, 512]             128\n",
      "             ReLU-78         [-1, 64, 512, 512]               0\n",
      "      double_conv-79         [-1, 64, 512, 512]               0\n",
      "               up-80         [-1, 64, 512, 512]               0\n",
      "           Conv2d-81         [-1, 27, 512, 512]           1,755\n",
      "          outconv-82         [-1, 27, 512, 512]               0\n",
      "================================================================\n",
      "Total params: 14,790,619\n",
      "Trainable params: 14,790,619\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.00\n",
      "Forward/backward pass size (MB): 3832.00\n",
      "Params size (MB): 56.42\n",
      "Estimated Total Size (MB): 3891.42\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = UNet(3, 27).float()\n",
    "summary(model,(3,512,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0965ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = BCEDiceLoss(eps=1.0, activation=None)\n",
    "optimizer = RAdam(model.parameters(), lr = 0.005)\n",
    "current_lr = [param_group['lr'] for param_group in optimizer.param_groups][0]\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.2, patience=2, cooldown=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d274ec2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89a3b97967904d7b88f76dea426195b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s, train_loss=0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-a59fe2b71764>:50: UserWarning: This overload of addcmul_ is deprecated:\n",
      "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:1050.)\n",
      "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c661cdac644b2f9ae57c4f0a5b1b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s, dice_score=0, val_loss=0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  Training Loss: 1.199891  Validation Loss: 0.798123 Dice Score: 0.333318\n",
      "Validation loss decreased (inf --> 0.798123).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ddf187350243dbbbbfef0d4ea8bbc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s, train_loss=0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff1494c1d4548edbfcd5863cbcd57d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s, dice_score=0, val_loss=0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2  Training Loss: 0.624776  Validation Loss: 0.578700 Dice Score: 0.528009\n",
      "Validation loss decreased (0.798123 --> 0.578700).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "156ed3cfefb84bf5b287b66532552ead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s, train_loss=0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 20\n",
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "dice_score_list = []\n",
    "lr_rate_list = []\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    dice_score = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    bar = tq(train_loader, postfix={\"train_loss\":0.0})\n",
    "    for data, target in bar:\n",
    "        \n",
    "        optimizer.zero_grad()# forward pass: compute predicted outputs by passing inputs to the model\n",
    "        \n",
    "        output = model(data) \n",
    "        loss   = criterion(output, target)\n",
    "        \n",
    "        loss.backward()# backward pass: compute gradient of the loss with respect to model parameters\n",
    "        \n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        bar.set_postfix(ordered_dict={\"train_loss\":loss.item()})\n",
    "\n",
    "    model.eval()\n",
    "    del data, target\n",
    "    with torch.no_grad():\n",
    "        bar = tq(val_loader, postfix={\"val_loss\":0.0, \"dice_score\":0.0})\n",
    "        for data, target in bar:\n",
    "   \n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # update average validation loss \n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "            dice_cof = dice_no_threshold(output.cpu(), target.cpu()).item()\n",
    "            dice_score +=  dice_cof * data.size(0)\n",
    "            bar.set_postfix(ordered_dict={\"valid_loss\":loss.item(), \"dice_score\":dice_cof})\n",
    "    \n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    valid_loss = valid_loss/len(val_loader.dataset)\n",
    "    dice_score = dice_score/len(val_loader.dataset)\n",
    "    train_loss_list.append(train_loss)\n",
    "    valid_loss_list.append(valid_loss)\n",
    "    dice_score_list.append(dice_score)\n",
    "    lr_rate_list.append([param_group['lr'] for param_group in optimizer.param_groups])\n",
    "    \n",
    "    # print training/validation statistics \n",
    "    print('Epoch: {}  Training Loss: {:.6f}  Validation Loss: {:.6f} Dice Score: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss, dice_score))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'MODEL_AUG_UNET.pt')\n",
    "        valid_loss_min = valid_loss\n",
    "    \n",
    "    scheduler.step(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04ec647",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot([i[0] for i in lr_rate_list])\n",
    "plt.ylabel('learing rate during training', fontsize=22)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3179842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(train_loss_list,  marker='o', label=\"Training Loss\")\n",
    "plt.plot(valid_loss_list,  marker='o', label=\"Validation Loss\")\n",
    "plt.ylabel('loss', fontsize=22)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc9fe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(dice_score_list)\n",
    "plt.ylabel('Dice score')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
